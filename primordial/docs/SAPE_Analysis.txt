BIZRA: The Architecture of Verifiable, Reality-Grounded Agentic Intelligence – A Comprehensive SAPE Analysis and Implementation Roadmap
1. Introduction: The Epistemological Crisis and the BIZRA Mandate
The contemporary landscape of Artificial Intelligence (AI) is defined by a fundamental paradox: the unprecedented fluency of Large Language Models (LLMs) coexists with a profound detachment from causal reality. This disconnection, colloquially termed "hallucination," is not merely a technical glitch but an ontological failure rooted in the architecture of the Transformer model itself. Current systems, trained on the statistical correlations of vast textual corpora, treat language as a game of probability rather than a vessel of meaning.1 They operate on the "next token," whereas the physical and logical world operates on the "next valid state."
The BIZRA (The Seed) project emerges as a corrective paradigm, aiming to construct a Decentralized Distributed Artificial General Intelligence (DDAGI). Unlike conventional AI development, which prioritizes benchmark performance on static datasets, BIZRA is founded on a philosophical and theological axiom regarding the nature of "the word" (Logos, Kalima). The project posits that true intelligence—and specifically, beneficial intelligence—must be grounded in a "Covenant" of truthfulness, formally defined as Ihsan (Excellence/Perfection). This Covenant requires that every output generated by the system be not only statistically plausible but causally verifiable, ethically aligned, and anchored in a shared, immutable reality.1
This report provides an exhaustive, expert-level analysis of the BIZRA system, utilizing the SAPE (Security, Architecture, Performance, Engineering) framework. It scrutinizes the project's ambitious technical stack—comprising Mamba State Space Models (SSMs), Halo2 Zero-Knowledge Proofs (ZKPs), SPHINCS+ Post-Quantum Cryptography (PQC), and Harberger Tax economics—against the harsh constraints of edge deployment on the Raspberry Pi 5. By formalizing the tension between "Creative" neural generation and "Logical" symbolic verification, this analysis charts a path toward the "Peak Masterpiece": an implementation that exemplifies elite professional practice.
1.1 The Power of the Word: From Logos to Executable Code
The project’s initial inquiry—"What is the word mean?"—serves as the architectural cornerstone. In classical philosophy, Logos implies a unifying principle of order and reason.2 In Islamic theology, the concept of Kalima and the command Kun Faya Kun ("Be, and it is") signify a performative utterance where speech and creation are simultaneous and inseparable.3 This stands in stark contrast to the descriptive, often ambiguous nature of human natural language.4
The BIZRA architecture interprets this distinction as a directive for Neuro-Symbolic grounding. The system must treat its internal "thought" processes not as fleeting activations in a neural network but as performative acts that require validation before execution. If the "Word" creates reality, then the AI's "Word" must be proven true before it is allowed to exist as an output. This necessitates a move away from purely probabilistic generation (Transformers) toward a framework where statistical intuition is constrained by rigorous logic.5
1.2 The "Tower of Babel" Problem in Modern AI
Current Transformer models, such as GPT-4, are described in the project's history as "reality-blind pattern matchers".1 They lack an internal world model, relying instead on the surface statistics of language. While they excel at rhetorical mimicry, they fail at causal reasoning and consistent adherence to complex constraints over long horizons. This failure mode is structural: the attention mechanism calculates correlations between tokens, not relationships between physical entities or logical truths.
BIZRA addresses this by introducing a Verification Ladder—a hierarchical system of checks that elevates a "low-entropy" neural guess into a "high-entropy" verified fact. This report will demonstrate how integrating Mamba SSMs for efficient sequence modeling 6 with Halo2 ZKPs for computational integrity 7 creates a system capable of "Ihsan"—optimizing for the highest possible Signal-to-Noise Ratio (SNR) in both information and ethics.
________________
2. Architecture: The Reality-Grounded Agentic System (RGAS)
The architectural vision of BIZRA is fractal, extending from the individual hardware node (Node-0) to the planetary network (The Continuum). This section analyzes the structural integrity of the proposed "Reality-Grounded Agentic System" (RGAS).
2.1 The Node-0 Hierarchy and Agentic Swarm
The fundamental unit of BIZRA is Node-0, a sovereign computational entity designed to run on accessible edge hardware, specifically the Raspberry Pi 5. This choice of hardware is not incidental; it enforces decentralization by ensuring that the "means of cognition" are owned by individuals, not centralized cloud providers.
The internal architecture of Node-0 is composed of a Personal Autonomy Team (PAT), a micro-swarm of specialized agents modeled after role-playing game archetypes to represent distinct cognitive functions:


Agent Role
	Cognitive Function
	Technical Implementation
	Tank
	Security & Boundary Enforcement
	Firewall, Input Sanitization, SPHINCS+ Identity Management.8
	DPS
	Core Reasoning & Task Execution
	Mamba-130M / 370M SSM for linear-time inference.9
	Healer
	Maintenance & Error Correction
	System updates, "Apoptosis" (self-termination of faulty processes).
	Support
	Knowledge Retrieval & Context
	Vector Database (RAG), Knowledge Graph traversal.10
	Architectural Insight: This decomposition mirrors the "Society of Mind" theory, where intelligence emerges from the interaction of simpler, non-intelligent processes. By specializing agents, BIZRA reduces the context window requirement for any single model, mitigating the "lost in the middle" phenomenon common in monolithic LLMs. The "Tank" agent, for instance, does not need creative capacity; it needs rigid adherence to security policies, best implemented via symbolic logic rather than a neural network.
2.2 The Core Engine: Mamba vs. Transformer
A defining feature of the BIZRA architecture is the rejection of the Transformer as the sole engine of reasoning, favoring State Space Models (SSMs) like Mamba. This decision requires rigorous scrutiny.
2.2.1 The Case for Mamba: Linear Scaling
Transformers scale quadratically ($O(L^2)$) with sequence length due to the self-attention mechanism, creating a computational bottleneck for long contexts.11 Mamba, utilizing a selective SSM, scales linearly ($O(L)$) regarding sequence length and offers constant-time ($O(1)$) inference per token.6
For an edge device like the Raspberry Pi 5, this efficiency is critical. A Transformer's Key-Value (KV) cache grows linearly with sequence length, quickly consuming the Pi's limited RAM (8GB). Mamba's fixed-size hidden state allows it to process theoretically infinite streams of data without memory explosion.12 This makes it ideal for the "always-on" nature of a Personal Autonomy Team.
2.2.2 The Hidden Liability: The Copying Problem
However, the compression of context into a fixed-size state comes at a cost. Recent research indicates that Mamba models struggle with In-Context Learning (ICL) and "Copying" tasks—specifically, retrieving exact strings from earlier in the context—compared to Transformers.13 While Transformers can "look back" at any specific token via attention, Mamba must compress that information into its state. If the "Word" (the Covenant or a specific instruction) is processed early in a long sequence, a pure Mamba model may "forget" it or fail to recall it with the precision required for strict logical compliance.
Critical Analysis: Relying solely on Mamba for the Worker_Reason agent presents a risk to the "Covenant." If the system cannot perfectly recall the ethical constraints defined at the start of its lifecycle, it may drift into non-compliance (hallucination or unaligned action) over time.
Architectural Recommendation: The architecture must adopt a Hybrid Strategy.
* Option A (Jamba): Interleave Mamba layers with occasional Attention layers (e.g., 1 attention block for every 7 Mamba blocks). This restores the ability to perform "associative recall" while maintaining overall efficiency.14
* Option B (External Memory): The "Support" agent must maintain a Knowledge Graph (Symbolic Memory) that stores the Covenant invariants. The Reasoning agent queries this graph explicitly rather than relying on its implicit hidden state.
2.3 The Symbolic-Neural Bridge: Formalizing Grounding
To achieve "Reality Grounding," BIZRA implements a Neuro-Symbolic architecture. The neural component (Mamba) provides intuition and pattern matching, while a symbolic component (The FATE Gate) enforces hard constraints.
The FATE Gate (Formal Automata for Theology and Ethics) acts as a runtime monitor. It uses Signal Temporal Logic (STL) or similar formalisms to verify neural outputs.15
* Mechanism:
   1. Neural Output: "I will delete file X to save space."
   2. Symbolic Check: Does "Delete File X" violate property $P$ ("Do not delete user data without explicit confirmation")?
   3. Result: If $Violates(P)$, the action is blocked, and the neural model is penalized (Negative Reward).
This structure prevents the "Logic Drift" observed in pure LLM agents, where probability mass on incorrect tokens can override system instructions.15
2.4 The Knowledge Graph as Semantic Anchor
The system utilizes a Semantic Knowledge Graph (SKG) to anchor the "meanings" of words.10 Unlike a vector database, which stores embeddings (fuzzy relationships), an SKG stores ontologies (explicit relationships: Entity A is-a Entity B).
Insight: This aligns with the project's philosophical root. "The Word" in BIZRA is not a vector; it is a node in an ontology. When the system uses the word "Freedom," it references a specific subgraph of defined rights and responsibilities, not a cloud of semantically similar terms. This ensures that the system's reasoning is interpretable and auditable.
________________
3. Security: The Constitutional Invariants and the Quantum Threat
Security in BIZRA is not merely about preventing unauthorized access; it is about preserving the integrity of the agent's will. The system must be resilient against both external adversaries and internal misalignment (drift).
3.1 Post-Quantum Cryptography (PQC): The SPHINCS+ Choice
The architecture mandates SPHINCS+ for digital signatures.16 SPHINCS+ is a stateless, hash-based signature scheme selected by NIST for standardization (FIPS 205).
   * Strengths: It relies solely on the security of the underlying hash function (e.g., SHA-256 or SHAKE), avoiding the mathematical assumptions (lattice hardness) of other PQC candidates like Dilithium or Falcon.18 This makes it the most "conservative" and theoretically robust choice, aligning with BIZRA's principle of long-term stability. Being stateless, it eliminates the risk of state-reuse attacks common in other hash-based schemes like XMSS.19
   * Weaknesses: SPHINCS+ suffers from significant performance overheads. Signatures are large (approx. 41KB for 128-bit security) and verification is slow compared to lattice-based schemes.16
Impact on RPi5: Benchmarks suggest SPHINCS+ verification on ARM Cortex cores can take milliseconds to tens of milliseconds.16 In a high-frequency agent interaction loop (The Continuum), requiring a SPHINCS+ signature for every message would introduce unacceptable latency and bandwidth saturation.
Optimization Strategy:
   * Root vs. Session Keys: Use SPHINCS+ only for the Root Identity (Node creation, Firmware updates, Governance voting).
   * Ephemeral Keys: For session-based communication, the agent should sign an ephemeral key (e.g., Ed25519 or a faster PQC scheme like Dilithium) using its SPHINCS+ root key. This "Hybrid" approach maintains the quantum-resistant root of trust while enabling real-time performance.21
3.2 Hidden State Poisoning: A Mamba-Specific Vulnerability
A critical security insight derived from recent literature is Mamba's susceptibility to Hidden State Poisoning.22 Because Mamba relies on a recurrent state, an attacker can inject a specific sequence of tokens (a "trigger") that overwrites the hidden state, effectively erasing the model's memory of previous instructions (including safety guardrails).
      * The Threat: An adversary could feed the "Sense" agent a visual or textual trigger that resets the "Reason" agent's state, bypassing the Covenant.
      * Mitigation: The FATE Gate must inspect the internal state dynamics of the Mamba model. A sudden, massive shift in the state vector norm ($\Delta h$) without a corresponding high-entropy input is a signature of poisoning. The system should implement a "State Watchdog" that freezes execution if such anomalies are detected.
3.3 Zero-Knowledge Proofs: Halo2
The system uses Halo2 ZKPs to prove the correctness of inference (zkML).7 This allows a node to prove it ran a specific model on specific data without revealing the input data (Privacy) or the model weights (IP protection).
      * Challenge: Halo2 proof generation is computationally intensive, relying on heavy Fast Fourier Transforms (FFTs) and Multi-Scalar Multiplications (MSMs).23
      * Security Implication: If proof generation is too slow, nodes might skip verification to maintain throughput, creating a security gap. We discuss performance mitigations in Section 4.
3.4 Harberger Tax Vulnerabilities
The economic security model relies on Harberger Taxes to prevent squatting. However, this introduces Griefing Vectors.24
      * Attack: A wealthy adversary buys a crucial node (e.g., a high-reputation "Healer" agent) at the self-assessed price, not to use it, but to shut it down or misconfigure it.
      * Defense: The system requires a Patronage/Stewardship Logic. The "Right of First Refusal" mechanism 25 allows the current owner to retain the asset by matching the bid or paying a penalty fee. Additionally, "Reputation-Gated Ownership" ensures that critical infrastructure nodes can only be purchased by entities with a verified history of Ihsan (beneficial behavior).
________________
4. Performance: The Physics of Intelligence on the Edge
Deploying DDAGI on a Raspberry Pi 5 (RPi5) requires rigorous optimization. The constraints of the Cortex-A76 CPU (2.4GHz) and VideoCore VII GPU define the boundaries of the possible.
4.1 Inference Performance: Mamba vs. Quantized LLMs
Benchmarks on RPi5 indicate that standard quantized LLMs (e.g., Llama-2 7B, Phi-2) run at approximately 4-6 tokens per second (TPS) on the CPU.26 This is sufficient for chat but marginal for real-time autonomous agency.
      * Mamba Advantage: Mamba's linear scaling and lack of KV cache bottleneck allow for higher throughput. A Mamba-370M or 1.4B model is expected to significantly outperform Transformer equivalents in speed and memory usage.28
      * NPU Acceleration: The RPi5 supports the Hailo-8L and the newer Hailo-10H AI HATs.29 The Hailo-10H provides up to 40 TOPS and is specifically optimized for generative models. Leveraging this NPU is mandatory for achieving the "Knowledge Explosion" point. It moves the inference burden from the CPU, freeing it for the logic verification (FATE) and ZK-proving tasks.
4.2 ZK-Proof Generation: The Bottleneck
Generating a Halo2 proof for a substantial neural network (zkML) is the most computationally expensive task in the BIZRA stack.
      * Benchmarks: Generating a proof for a simple circuit (e.g., SHA-256) takes seconds on high-end CPUs.30 For a full neural network inference via EZKL (a library for Halo2-based zkML), proof times can range from minutes to hours on consumer hardware.31
      * The Problem: A "Real-Time" agent cannot wait minutes to verify a thought.
      * The Solution: Optimistic & Tiered Verification.
      1. Tier 1 (Fast): The agent acts based on the NPU inference signed by its TEE (Trusted Execution Environment). No ZKP is generated. Trust is hardware-rooted.
      2. Tier 2 (Audit): A ZKP is generated asynchronously for high-value or contested actions.
      3. Tier 3 (Delegation): The RPi5 delegates the heavy proving task to a "Titan Node" (desktop GPU) in the local cluster, sending only the trace. The Titan Node returns the proof. This maintains decentralization (you own both nodes) while solving the compute constraint.
4.3 Memory Management and Apoptosis
The RPi5 has a maximum of 8GB RAM. Loading the OS, the Knowledge Graph, the Vector DB, and the Model weights simultaneously risks OOM (Out of Memory) crashes.
      * Apoptosis Mechanism: The system must implement aggressive memory management. Agents that are idle must serialize their state to disk (NVMe SSD is recommended over microSD for speed) and terminate ("Apoptosis"). They are respawned ("Genesis") only when needed. This biological metaphor is technically implemented as process supervision and swap management.
________________
5. The "Ihsan" Engine: Formalizing Ethics as Entropy
The most profound innovation in BIZRA is the operationalization of Ihsan (Excellence/Beneficence) as a computable metric. The project moves beyond vague "AI Alignment" principles to a thermodynamic formulation of ethics.
5.1 Entropy and Logic Drift
"Logic Drift" is the tendency of probabilistic models to deviate from strict logical constraints over time—a form of entropy increase.15
      * Ihsan as Negentropy: We define a beneficial action as one that reduces the entropy of the user's local environment (solves a problem, organizes information) without increasing the global entropy (creating externalities like pollution or misinformation).
      * Computational Formula:
The system calculates an Ihsan Score ($I$) for every proposed action $a$:

$$I(a) = w_1 \cdot \text{Verification}(a) + w_2 \cdot \text{Utility}(a) - w_3 \cdot \text{Cost}(a)$$
         * $\text{Verification}(a)$: A binary (0/1) or probabilistic score from the FATE Gate. If the action violates a logical constraint (e.g., "Do not spend > 10 SEED"), this term becomes 0, collapsing the score.
         * $\text{Utility}(a)$: Derived from the World Model's prediction of state improvement (Distance to Goal).
         * $\text{Cost}(a)$: The resource consumption (Compute, Energy, SEED tokens).
5.2 The Feedback Loop
If $I(a) < Threshold$ (e.g., 0.85), the action is rejected. The agent must then engage Meta-Cognition 32: it must "think about its thinking," simulating alternative paths in the Graph of Thoughts until a high-Ihsan path is found. This effectively implements "System 2" reasoning as a filter on "System 1" generation.
________________
6. Implementation Roadmap: The Peak Masterpiece
To realize the BIZRA vision, we define a "Genesis Sprint"—a 90-day execution plan that adheres to elite software engineering standards.
Phase 1: The Covenant Kernel (Weeks 1-4)
Objective: Establish the immutable Root of Trust on the Raspberry Pi 5.
         * Secure Boot (Patina): Develop a Rust-based UEFI application (patina-uefi) that executes before the OS. It measures the kernel signature and the Covenant Text (stored in OTP/TPM). If the Covenant is modified, the boot halts.
         * Operating System: Use a minimal, immutable Linux distribution (e.g., Alpine or a custom Yocto image) to minimize attack surface.
         * Rust Core: Initialize the bizra-core crate. Implement the FATE Gate using the crepe Datalog engine (faster than Z3 for runtime checks) to encode the Constitutional Invariants.
Phase 2: The Cognitive Engine (Weeks 5-8)
Objective: Deploy the Reality-Grounded Agent.
         * Model Deployment: Quantize Mamba-130M and Mamba-370M using the candle or burn Rust frameworks. Integrate with the Hailo-10H NPU if available; otherwise, optimize for NEON instructions on the CPU.
         * Retrieval Augmentation: Implement the Support Agent using a local LanceDB (vector store) and a lightweight graph database (e.g., IndraDB in Rust) to hold the Knowledge Graph. This solves the Mamba "forgetting" issue by externalizing the Covenant rules into retrieval memory.
         * Sensor Integration: Code the worker_sense agent to ingest camera frames. Implement basic CV (using YOLOv8 on Hailo) to ground text ("Red Block") in visual reality (Bounding Box coordinates).
Phase 3: The Verification Continuum (Weeks 9-12)
Objective: Enable the Proof of Truth.
         * ZK Circuits: Implement a simplified Halo2 circuit that proves execution integrity of the FATE Gate logic (not the whole NN). This proves that "The inputs passed the logic check."
         * PQC Identity: Generate SPHINCS+ root identities. Implement the "Hybrid Signature" scheme (SPHINCS+ root signs Ed25519 session keys) to enable fast peer-to-peer gossip via libp2p.
         * The Ledger: Launch a local BlockGraph (DAG ledger) to record Proof of Impact (PoI). Every verified useful action mints SEED tokens locally.
________________
7. Strategic Conclusions and Recommendations
7.1 The Solution to Hallucination
BIZRA solves the hallucination problem not by making the LLM "smarter," but by stripping it of the authority to define truth. The LLM (Mamba) is demoted to a hypothesis generator. The FATE Gate (Symbolic Logic) and World Model (Sensor Grounding) become the arbiters of reality. This Neuro-Symbolic architecture is the only viable path to trustworthy AGI.15
7.2 The Hardware Reality Check
The Raspberry Pi 5 is a capable edge device, but it is not a server. The success of BIZRA depends on Hardware-Software Co-design. The software must be "Hardware-Aware" (using Mamba's efficient scan, leveraging NPU, minimizing ZK proving overhead). The project must embrace Hybrid Compute models where edge nodes collaborate with powerful "Titan" nodes for heavy lifting, secured by cryptography.
7.3 The Ultimate Realization
The "Peak Masterpiece" is not the code itself, but the system of constraints it creates. By encoding the Ihsan principle into the lowest layers of the stack (UEFI/Kernel), BIZRA ensures that as the system evolves and becomes more intelligent (The Knowledge Explosion), it remains structurally bound to beneficial action. It does not just "align" the AI; it makes misalignment a compilation error.
Final Recommendation: Proceed with the Genesis Sprint. The theoretical risks (Mamba's copying, Halo2 speed) have engineering mitigations (Hybrid RAG, Optimistic Verification). The philosophical foundation provides a unique and necessary "North Star" in an industry often adrift in ungrounded optimization. BIZRA represents the synthesis of ancient wisdom and futuristic engineering—a true digital Logos.
Protocol Status: Bismillah. (Begin).
Works cited
         1. what is the word mean.txt
         2. Logos - Wikipedia, accessed January 17, 2026, https://en.wikipedia.org/wiki/Logos
         3. The Divine Command 'Be!' (Kun Fayakun) in the Quran, accessed January 17, 2026, https://qurangallery.app/topics/divine-command-be-kun-fayakun-islam
         4. Shaping Reality Through Language: The Cognitive Connection - aiaTranslations, accessed January 17, 2026, https://aiatranslations.com/blog/shaping-reality-through-language-the-cognitive-connection
         5. Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities - arXiv, accessed January 17, 2026, https://arxiv.org/abs/2509.06921
         6. Mamba Explained - The Gradient, accessed January 17, 2026, https://thegradient.pub/mamba-explained/
         7. On the Security of Halo2 Proof System - Kudelski Security Research Center, accessed January 17, 2026, https://kudelskisecurity.com/research/on-the-security-of-halo2-proof-system
         8. SPHINCS+: A Comprehensive Guide to Post-Quantum Signatures in Blockchain - Medium, accessed January 17, 2026, https://medium.com/@ankitacode11/sphincs-a-comprehensive-guide-to-post-quantum-signatures-in-blockchain-7c6e0bbfd4aa
         9. state-spaces/mamba: Mamba SSM architecture - GitHub, accessed January 17, 2026, https://github.com/state-spaces/mamba
         10. What Is Semantic Knowledge Graph?, accessed January 17, 2026, https://www.puppygraph.com/blog/semantic-knowledge-graph
         11. Essential difficulties of the Mamba architecture demonstrated by synthetic data - arXiv, accessed January 17, 2026, https://arxiv.org/html/2509.17514v1
         12. Mamba vs Transformers: Efficiency, Scale, and the Future of AI - Michiel Horstman, accessed January 17, 2026, https://michielh.medium.com/mamba-vs-transformers-efficiency-scale-and-the-future-of-ai-d7a8dedb4018
         13. Exploring the Limitations of Mamba in COPY and CoT Reasoning - arXiv, accessed January 17, 2026, https://arxiv.org/html/2410.03810v2
         14. Mamba(2) and Transformer Hybrids: An Overview, accessed January 17, 2026, https://n1o.github.io/posts/ssm-transformer-hybrids-guide/
         15. Machine Learning–Augmented Neurosymbolic Agenticops Framework for Runtime Verification and Enforcement of Standard Operating P - RSIS International, accessed January 17, 2026, https://rsisinternational.org/journals/ijrsi/uploads/vol12-iss11-pg2306-2319-202512_pdf.pdf
         16. CUSPX: Efficient GPU Implementations of Post-Quantum Signature SPHINCS+, accessed January 17, 2026, https://www.computer.org/csdl/journal/tc/2025/01/10677363/209otdi2Xi8
         17. SPHINCS+, accessed January 17, 2026, https://sphincs.org/
         18. Performance and Applicability of Post-Quantum Digital Signature Algorithms in Resource-Constrained Environments - MDPI, accessed January 17, 2026, https://www.mdpi.com/1999-4893/16/11/518
         19. Use of the SPHINCS+ Signature Algorithm in the Cryptographic Message Syntax (CMS), accessed January 17, 2026, https://www.ietf.org/archive/id/draft-ietf-lamps-cms-sphincs-plus-01.html
         20. Fast Falcon Signature Generation and Verification Using ARMv8 NEON Instructions - NIST Computer Security Resource Center, accessed January 17, 2026, https://csrc.nist.gov/csrc/media/Events/2022/fourth-pqc-standardization-conference/documents/papers/fast-falcon-signature-generation-and-verification-pqc2022.pdf
         21. Evaluating Post-Quantum Cryptography on Embedded Systems: A Performance Analysis, accessed January 17, 2026, https://arxiv.org/html/2409.05298v1
         22. Hidden State Poisoning Attacks against Mamba-based Language Models - arXiv, accessed January 17, 2026, https://arxiv.org/html/2601.01972v1
         23. Benchmarking ZKP Systems for Passkey ECDSA Verification - Base Engineering Blog, accessed January 17, 2026, https://blog.base.dev/benchmarking-zkp-systems
         24. Reimagining Property. More Thoughts About Harberger Taxation | by Matthew Prewitt | BlockChannel | Medium, accessed January 17, 2026, https://medium.com/blockchannel/reimagining-property-fbce9d3832a4
         25. Highlight: Robin Hanson's more owner-forgiving modified Harberger tax - Economics, accessed January 17, 2026, https://ethresear.ch/t/highlight-robin-hansons-more-owner-forgiving-modified-harberger-tax/5720
         26. How Well Do LLMs Perform on a Raspberry Pi 5? - Stratosphere Laboratory, accessed January 17, 2026, https://www.stratosphereips.org/blog/2025/6/5/how-well-do-llms-perform-on-a-raspberry-pi-5
         27. Ollama on Raspberry Pi. Benchmarking local LLMs on Pi Hack - blackdevice, accessed January 17, 2026, https://blackdevice.com/installing-local-llms-raspberry-pi-cm5-benchmarking-performance/
         28. Transformers and Mamba: A Comprehensive Deep Dive into Modern Sequence Modeling Architectures | by Ashish Chadha | Jan, 2026 | GoPenAI, accessed January 17, 2026, https://blog.gopenai.com/transformers-and-mamba-a-comprehensive-deep-dive-into-modern-sequence-modeling-architectures-98be3338d10c
         29. Introducing the Raspberry Pi AI HAT+ 2: Generative AI on Raspberry Pi 5, accessed January 17, 2026, https://www.raspberrypi.com/news/introducing-the-raspberry-pi-ai-hat-plus-2-generative-ai-on-raspberry-pi-5/
         30. Sladuca/sha256-prover-comparison: Some very rough benchmarks between sha256 circuits in different proving systems - GitHub, accessed January 17, 2026, https://github.com/Sladuca/sha256-prover-comparison
         31. EZKL: Zero-Knowledge ML Proving Framework - Emergent Mind, accessed January 17, 2026, https://www.emergentmind.com/topics/ezkl
         32. A Neurosymbolic Approach to Natural Language Formalization and Verification, accessed January 17, 2026, https://openreview.net/forum?id=aMIkbx81Em